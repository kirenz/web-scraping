{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://developer.nytimes.com/get-started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_URI(query:str, page_num:str, date:str, API_KEY:str) -> str:\n",
    "    \"\"\"# obtain the URI for access to articles for a given query, page number, and date\"\"\"\n",
    "    \n",
    "    # append query to uri\n",
    "    URI = f'https://api.nytimes.com/svc/search/v2/articlesearch.json?q={query}'\n",
    "    \n",
    "    # add page_num and date parameters\n",
    "    URI = URI + f'&page={page_num}&begin_date={date}&end_date={date}'\n",
    "    \n",
    "    # add API key\n",
    "    URI = URI + f'&api-key={API_KEY}'\n",
    "    \n",
    "    # return the new URI \n",
    "    return URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the API only providing 10 articles per request, we need to make multiple requests until we have collected all of the data, which is then stored in a data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import datetime \n",
    "\n",
    "# create a dataframe that will store all articles \n",
    "df = pd.DataFrame()\n",
    "\n",
    "# get current date\n",
    "current_date = datetime.datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "# collect data from all available pages\n",
    "page_num = 1\n",
    "while True:\n",
    "    # get the URI needed for the articles related to Winter Olympics from newest to oldest\n",
    "    URI = get_URI(query='COVID', page_num=str(page_num), date=current_date, API_KEY=API_KEY)\n",
    "\n",
    "    # make a request with the url\n",
    "    response = requests.get(URI)\n",
    "\n",
    "    # collect the data from the response in JSON format\n",
    "    data = response.json() \n",
    "\n",
    "    # convert data to a data frame\n",
    "    df_request = json_normalize(data['response'], record_path=['docs'])\n",
    "\n",
    "    # end loop if no new articles are available \n",
    "    if df_request.empty:\n",
    "        break\n",
    "\n",
    "    # append df_request to the dataframe\n",
    "    df = pd.concat([df, df_request])\n",
    "\n",
    "    # pause to stay within the limit of number of requests\n",
    "    time.sleep(6)\n",
    "\n",
    "    # go to the next page\n",
    "    page_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for and replace any duplicate articles\n",
    "if len(df['_id'].unique()) < len(df):\n",
    "    print('There are duplicates in the data')\n",
    "    df = df.drop_duplicates('_id', keep='first')\n",
    "\n",
    "# search for and replace articles with missing headlines\n",
    "if df['headline.main'].isnull().any():\n",
    "    print('There are missing values in this dataset')\n",
    "    df = df[df['headlinee.main'].isnull()==False]\n",
    "\n",
    "# filter out any op-eds\n",
    "df = df[df['type_of_material']!='op-ed']\n",
    "\n",
    "# keep only headline, publication_date, author name, and url\n",
    "df = df[['headline.main', 'pub_date', 'byline.original', 'web_url']]\n",
    "\n",
    "# rename columns\n",
    "df.columns = ['headline', 'date', 'author', 'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jankirenz/lectures/python-notebooks/web_scraping/nyt/nyt.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jankirenz/lectures/python-notebooks/web_scraping/nyt/nyt.ipynb#ch0000009?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is now in an acceptable format, it should be stored in a relational database (PostgreSQL in this case) for future use. To achieve this, we will need to implement object relational mapping (ORM), which can be done with the SQLAlchemy module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create engine for database\n",
    "database_loc = f\"postgresql://{username}:{password}@localhost:5432/{database}\"\n",
    "engine = create_engine(database_loc)\n",
    "\n",
    "# add data to database\n",
    "df_test.to_sql(name='news_articles',\n",
    "         con=engine,\n",
    "         index=False,\n",
    "         if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is sent to the provided location, it can be directly accessed with SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Preview of dataset in database\n",
    "SELECT *\n",
    "FROM news_articles\n",
    "LIMIT 5;"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "463226f144cc21b006ce6927bfc93dd00694e52c8bc6857abb6e555b983749e9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
